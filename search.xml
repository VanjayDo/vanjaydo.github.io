<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[校园网中实现免费上网的方法（二）]]></title>
    <url>%2F%2Fpost%2F%E6%A0%A1%E5%9B%AD%E7%BD%91%E4%B8%AD%E5%AE%9E%E7%8E%B0%E5%85%8D%E8%B4%B9%E4%B8%8A%E7%BD%91%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%8C%EF%BC%89.html</url>
    <content type="text"><![CDATA[该方法需要拥有校内服务器,且该服务器能正常访问外网.原理很简单,就是访问不需要花钱的内网,然后将流量全部发到校内服务器上,让该服务器做代理进行请求转发.该方法不讨论ipv6,因为在校园网有v6地址你就已经可以免费上网了. 代理服务器设置google搜索关键词 “shadowsocks 搭建 代理服务器” 本地配置 安装ss,配置代理服务器为校内的那台服务器地址即可,各项配置正确即可在能访问服务器的前提下访问到百度一类未被墙的网站. 这时浏览器能上网但是其他软件(像迅雷/百度网盘)没法上网怎么回事?首先要提一下ss在本地实现代理的机制.以Windows系统为例,设置里有“系统代理”的选项，如果启用该选项,填上相应的配置,那么系统会自动在浏览器的设置里添加代理地址,可以这样查看,这样的话，浏览器和其他的支持这种代理设置的软件就会在访问网络时将流量发到代理地址上,但是实际上,支持系统代理的软件非常少,一般来说只被浏览器普遍支持(所以你知道为什么直接启用ss后除了浏览器为什么其他软件都不走ss代理)。说明了这些,那么ss怎样实现在本地的代理就很容易明白了,你第一次运行ss,它会自动设置系统代理,代理地址为本地回环地址加上端口(默认为1080,可手动更改),那么浏览器的流量发到这个代理地址后,ss进行处理(根据代理规则出口流量与加密等),其实localhost:1080后面还跟了一个文件,它就是PAC里面定义了至少一个JS函数,代理规则也都在里面,它通过JS函数来确定访问每个URL时所选用的合适代理,再将流量出口.知道了这些,你就应该明白,如果想要其他软件也用上系统代理,那么我们需要将这些软件的流量也转发到系统代理的地址上.在此我选择了proxifier来进行可选择性的代理.具体的使用请自己搜索. 但是此时你只能访问未被墙的网站,因为你的代理服务器在墙内. 二次代理想上google的解决办法当然就是二次代理了,有两种实现办法: 1.我先将流量发到自己的校内服务器上,再配置校内服务器,让它把流量发到墙外的代理服务器; 2.我直接在自己的PC上挂两个SS客户端,一个配墙外代理服务器(占1080端口),一个配校内服务器(占1081端口),流量都发到1080端口,利用pac进行选择性代理,然后利用ss客户段端设置中的Forward proxy添加一个本地1081端口的sock5代理,让1080端口的流量经过选择性代理后再全部发送到1081端口通过校内服务器出口到外网. 对于第一种方法,这里贴一个GitHub项目,它只要一条命令就可以实现二次代理,需要注意的是使用转发功能之前需要先切换到develop分支. 但是第一种方法在我的使用过程中体验并不好,第一,速度比较慢(可能是我那台服务器年纪比较大,计算处理能力较低,所以两次加密处理起来比较慢);第二,就是如果你的墙外代理服务器有多台就需要开多个端口;所以我放弃了法一,采用了法二,大概过程在上面已经说了,在此不赘述;对于proxifier的规则配置说两点,首先,default选项填1080端口;如果像我一样需要校园认证等操作不需要走代理(我这边这种过程是不能走代理,因为学校的校园网认证对于ip段做了跳转,如果是服务器一类的地址去访问则直接跳转到学校官网首页而非认证校园网登录页面)就新增加一条规则,将其action设为direct,其中的target hosts对于ip地址或网址进行匹配. 自动注册热键的ss客户端在github的shadowsocks-windows项目中下载的版本到目前为止是没有自动注册热键功能的,也就是你设置热键后每次重启电脑都要手动重新注册一下,对有热键需求的人来说肯定不方便,但是自动注册的功能已经被voq开发出了,GitHub项目在此.基于此,我用appveyor编译了一下, 生成了exe文件,appveyor项目在此,debug版比release版报错更详细,exe文件下载链接在artifacts里面,有需要的可以下载. 手机怎么办在此以IOS系统为例介绍,Android类似.我使用的代理软件是Shadowrocket,现在app store上已经封停了,无法下载,可以使用各类助手,如果自己当前使用的助手平台上也被封了,可以下载我从pp助手获得的ipa文件-&gt;下载链接.需要注意的是,代理规则应该是默认全部代理,对于一些特定的网址(如校园网的认证登录网址)应该进行匹配直连(direct).而在shadowrocket的使用中,我发现使用FINAL进行默认的规则并不可行,如配置文件这样写: [Rule] IP-CIDR,127.0.0.1,DIRECT FINAL,PROXY 这表示我希望除了发到127.0.0.1回环地址的流量进行直连外,其他的全都进行代理;然而实际却并不可行,它对其他的流量并不会进行默认代理,不知道是不是软件本身的问题.在此我对域名后缀进行了关键字匹配,只要是使用域名访问的都进行转发(反正常用的域名后缀就那么多个),如DOMAIN-KEYWORD,com,PROXY,这样在访问所有.com域名后缀的站点时都走代理. 根据报错来设置代理规则例如比如我使用命令hexo s来启用heox本地服务器查看刚更新的内容效果时，访问localhost:4000站点网页打不开或者网页内容显示不完全，在这种情况下就要怀疑是代理的问题了，去查proxifier日志（建议在proxifier菜单栏中的log一栏里将file log选择为Errors only,这样就会把报错日志保存到本地文件中，查起来很方便），其中显示： [12.01 17:15:10] chrome.exe *64 - [::1]:4000 (IPv6) close, 335 bytes sent, 0 bytes received, lifetime 00:01 [12.01 17:15:10] chrome.exe *64 - [::1]:4000 (IPv6) close, 0 bytes sent, 0 bytes received, lifetime 00:01 [12.01 17:15:10] chrome.exe *64 - [::1]:4000 (IPv6) open through proxy 127.0.0.1:1080 SOCKS5 [12.01 17:15:10] chrome.exe *64 - [::1]:4000 (IPv6) open through proxy 127.0.0.1:1080 SOCKS5 [12.01 17:15:10] chrome.exe *64 - [::1]:4000 (IPv6) warning : GetSockName() cannot work properly for the IPv4-IPv6 mixed connection. 一看发现是访问本地v6地址的4000端口出现的问题（为什么要走v6地址的原因未知），那就很简单了，我们把::1(代表v6的本地回环地址,同v4的127.0.0.1)加入到Localhost中,规则设为direct 一些注意点注意如果使用过程中有些需要使用网络的软件发生异常(如启动不响应),应该要去查proxifier日志,看看是不是代理的问题,如果没有产生日志应该将所有代理关掉再重启异常的软件试试.]]></content>
      <tags>
        <tag>运用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins入门]]></title>
    <url>%2F%2Fpost%2Fjenkins%E5%85%A5%E9%97%A8.html</url>
    <content type="text"><![CDATA[之前使用AppVeyor实现了提交源码到仓库然后自动拉取、生成静态页面并推送到Github Pages仓库的功能，但是我想在自己的服务器上再做一个同步更新的博客站点，因为最近在学node，所以先开始想着用node写一个监听的服务器，然后利用githook来自动拉取代码，搜了下相关的库，果然有一个叫github-webhook-handler，操作了半天，一直报node版本的错，怎么调都不行……默默放弃了，还是选择了Jenkins（之前一直担心Jenkins会额外消耗比较多的资源，因为自己的云服务器配置较低，使用后感觉自己多虑了）。在此记录一下简单的使用过程。 安装Jenkins安装Ubuntu 安装： $ wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add - $ sudo echo &quot;deb http://pkg.jenkins.io/debian-stable binary/&quot; &gt; /etc/apt/sources.list.d/jenkins.list $ sudo apt update $ sudo apt install jenkins $ systemctl start jenkins 登录并创建账户安装后第一次使用需要手动获取密码来登录： $ cat /var/lib/jenkins/secrets/initialAdminPassword 得到密码密码后访问你服务器的8080端口（Jenkins默认8080端口，可以通过修改配置文件【Ubuntu下是/etc/default/jenkins】中的HTTP_PORT参数来指定），打开页面后提示你输入密码进行访问，将密码粘贴进去后进入操作界面：选择安装推荐的插件，或者你也可以自选：安装完成后会跳转到创建用户页面让你注册用户：“Save and Finish”后提示”Jenkins is ready！”之后如果要添加用户/修改密码可以在系统管理的管理用户里操作。 添加一个GitHub项目的构建创建自己github账户的access tokens关于生成personal access token的官网介绍。到你账户的settings -&gt; Developer settings -&gt; Personal access tokens，选择Generate new token,Token description可以填一些描述性文字，Select scopes里必选repo和admin:repo_hook两项（子内容全选），如下图：完成后点击Generate token，不出意外则跳转到生成成功页面，记住复制红框中生成的token： 添加github账号到jenkins为了能够使用我们的GitHub账号进行操作，我们需要在Jenkins系统设置中添加自己的github账户：系统管理 -&gt; 系统设置 -&gt; GitHub Servers ,如图：点击“Add GitHub Server”Name填自己的github用户名在Credentials选择Add一个Jenkins，其中Kind选择为Secret text，如图：将刚才生成的token粘贴进Secret栏中，点击add，添加成功。 完成后点击Test connection效果为： Credentials verified for user ****, rate limit: **** 给Jenkins添加权限编辑Jenkins配置文件(ubuntu下是/etc/default/jenkins),将 JENKINS_USER=$NAME 修改为 JENKINS_USER=&quot;root&quot; 保存退出后执行命令： $ chown -R root:root /var/lib/jenkins $ chown -R root:root /var/cache/jenkins $ chown -R root:root /var/log/jenkins $ service jenkins restart 即可。 添加一个Jenkins构建 在你的github项目里添加webhook:项目的settings中左边栏的webhooks,选择add webhook,Payload URL中填你的服务器地址(ip或域名)与jenkins端口再加上”/github-webhook”,如http://182.254.133.70:8080/github-webhook 点击jenkins左边栏中的”新建”，选择“构建一个自由风格的软件项目”，如图：点击”OK”，进入配置页面，源码管理选择Git, Repository URL:填上你项目的repo地址 Credentials:点击Add按钮添加一个Jenkins，Kind选择默认的Username with password将github的账号和密码填到相应的Username和Password中，点击Add完成添加。 构建触发器:选择GitHub hook trigger for GITScm polling,能够接收github在项目提交新的commit后推送的事件来自动触发构建 构建:选择添加自己需要的构建步骤，这里因为我需要的是自动拉取GitHub Pages库里的静态页面并部署到服务器上，所以我选择Execute shell，填上命令，如图： 保存后在左边面板上点击“立即构建”左下方Build History中结果前面的小球显示为蓝色则成功，为红则失败。 赘述如果你遇到了github server,webhook以及构建项目等配置都正确,但是构建中的”GitHub hook trigger for GITScm polling”触发器选项一直提示你webhook有问题,那么你应该考虑删掉这个构建项目,重新配置一遍试试.]]></content>
      <tags>
        <tag>CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[appveyor入门]]></title>
    <url>%2F%2Fpost%2Fappveyor%E5%85%A5%E9%97%A8.html</url>
    <content type="text"><![CDATA[之前对于备份hexo搭建的博客源码采用的方式是在Github Pages对应的库中新开一个分支，每当源码有重要的客制化变更时都推一次到备份的分支上，但是这样并不是一个好办法，因为，但是新开一个库专门存源码的话又不想每一次更新时推两次（一次到源码库，一次到GitHub Pages的静态页面库）怎么办？答案就是使用CI。我们直接推源码的更新到源码库，然后让CI工具自动拉取源码生成静态页面后再自动推到静态页面库中。如题，这里采用的CI工具是appveyor。 appveyor简介appveyor的特点就是操作全部上云, 与用户平台无关, 你可以在采用本地appveyor.yml配置文件(代码托管方[如github]必须提供了相关API)或在appveyor项目里配置两种方式对你的CI项目进行配置, 项目会运行在官方预安装了很多软件的虚拟机中;项目按照你的配置build完成后会将结果以邮件的方式反馈给你(有时延迟比较大, 需要等个二三十分钟). 反正我个人感觉非常好用, 非常非常好用, 嗯!具体的请自己去了解吧. 基本使用首先当然是注册账号了, 用github账号登录就好了(反正后面也是要绑定的). 创建一个项目这里以GitHub上的项目为例讲一下push commit到GitHub仓库后appveyor自动拉取项目并进行操作的过程: 登录上去后点NEW PROJECT添加项目; 在GitHub账户里选择项目, 点击ADD 在GitHub仓库里添加appveyor.yml配置文件, 因为配置的选项有很多, 具体的写法请查看appveyor文档, 这里只举一个很简单的例子:appveyor自动拉取github项目后, 在build之前列一下当前目录里的文件, 然后在build过程中只打印一句”this is just a test”.我们在GitHub仓库的根目录里添加一个文件, 取名为appveyor.yml, 然后在里面输入: before_build: - dir build_script: - echo &quot;this is just a test&quot; 然后保存, commit即可.随后我们到appveyor项目界面可以看到已经自动在运行了, console里会打印出如下类似内容Build started git clone -q --branch=master https://github.com/VanjayDo/test.git C:\projects\test git checkout -qf 65d495665aae3ead5e4ddc06c88a67246847b621 dir Volume in drive C is Windows Volume Serial Number is D4AB-4044 Directory of C:\projects\test 12/12/2017 01:54 AM &lt;DIR&gt; . 12/12/2017 01:54 AM &lt;DIR&gt; .. 12/12/2017 01:54 AM 68 appveyor.yml 1 File(s) 68 bytes 2 Dir(s) 40, 973, 512, 704 bytes free echo &quot;this is just a test&quot; &quot;this is just a test&quot; Discovering tests...OK Build success 这就算是一个成功的例子了, 整个配置文件很简单, 如果需要比较复杂的操作可以参考appveyor-yml的参考文档, 具体的也可以查appveyor docs 基本流程整个过程是这样的: 你添加自己的GitHub仓库后, appveyor会自动到该GitHub仓库的设置里添加一个webhook(触发事件默认为Pull request和Push), 与当前的appveyor项目绑定, 所以每当你有新的推送时, GitHub会自动触发该webhook; appveyor项目被触发后会先调用GitHub官方的api查看该repo根目录下是否有appveyor.yml配置文件, 如果有就先只下载该文件对项目环境进行配置, 然后clone该repo, 再进行项目的整个build;如果没有配置文件则默认使用msbuild, 即UI配置, 这需要你预先在项目设置里进行配置. 什么?UI配置和yaml配置能不能共存?你问这个啊, 官方文档里写的很清楚了:It’s worth noticing that both appveyor.yml and UI configuration are mutually exclusive. It’s always either YAML or UI - the settings from each are not merged. If you have appveyor.yml in your repo it will override all settings made on the UI unless explicitly disabled by Ignore appveyor.yml. There are few exceptions, which are:1.Environment variables. Variables defined on UI are getting merged with those ones defined in appveyor.yml. Variable values with the same names are getting overridden with values from UI.2.Notification settings defined on UI are getting merged with those ones defined in appveyor.yml.3.Build version format is taken from UI if it is not set in appveyor.yml.简而言之就是, 二者不能共存(不能合并), yaml配置文件的优先级更高, 如果有yaml配置则UI配置会全部失效(除非你在UI配置里选择忽略yaml配置文件), 当然, 除了最后列出的三点例外(环境变量[两者都有则合并], 提醒[两者都有则合并]和build版本[yaml没写而UI配置了则用UI的]). 要推送artifacts怎么办如果你需要在build完成之后将成功生成的产品发布/推送到你的GitHub仓库的话, 那就还需要进一步设置.在官方文档的Git push from build也说明了, 这里我以hexo博客为例进行具体说明, 我创建了hexo源码库与静态页面库两个repo, 将源码和博客站点分开, 想要的效果是: 我主动推送更新到源码库中之后, appveyor自动拉取帮我生成静态页面然后推到静态页面库中, 这样博客站点就自动更新了, 这个过程大概是: hexo源码库更新后触发webhook; appveyor项目自动拉取appveyor.yml对环境进行配置, 然后clone项目; 在install部分用npm安装一系列依赖, 在build_script部分生成静态页面, 在on_success部分定义生成成功后进行推送的步骤; build其实主要是hexo g来生成静态页面, 也可能你需要后期处理一下(如压缩代码), 完成build后会将之前定义的artifacts文件夹中的内容(在这里是public文件夹, 即静态页面生成后存放的文件夹)推送到静态页面库中, 大功告成 其实, 整个过程和上面的基本流程相比也就是多了一个推送的步骤而已, 想想, 如果你需要commit到仓库, 除了登录到GitHub还能用什么办法?那就是OAuth token了, 也就是personal access token, 能够通过GitHub认证, 拿到用户完全的操作权限. 具体的操作如下: 生成personal access token基本操作, 不会的请参考官方文档保存生成的token,等会用 加密生成的token到Appveyor加密页面对刚刚生成的token进行加密(加密后的token才能放心的写到appveyor.yml配置文件里)对于这个Encrypt data, 官方文档里也有说明在此.保存加密的token,等会用 配置文件这里我也是在网上复制的配置文件,反正比我写的条理多了 clone_depth: 1 environment: access_token: secure: [填上刚刚加密后的token] install: - node --version - npm --version - npm install - npm install hexo-cli -g build_script: - hexo g artifacts: - path: public on_success: - git config --global credential.helper store - ps: Add-Content &quot;$env:USERPROFILE\.git-credentials&quot; &quot;https://$($env:access_token):x-oauth-basic@github.com`n&quot; - git config --global user.email &quot;%GIT_USER_EMAIL%&quot; - git config --global user.name &quot;%GIT_USER_NAME%&quot; - git clone --depth 5 -q --branch=%TARGET_BRANCH% %STATIC_SITE_REPO% %TEMP%\static-site - cd %TEMP%\static-site - del * /f /q - for /d %%p IN (*) do rmdir &quot;%%p&quot; /s /q - SETLOCAL EnableDelayedExpansion &amp; robocopy &quot;%APPVEYOR_BUILD_FOLDER%\public&quot; &quot;%TEMP%\static-site&quot; /e &amp; IF !ERRORLEVEL! EQU 1 (exit 0) ELSE (IF !ERRORLEVEL! EQU 3 (exit 0) ELSE (exit 1)) - git add -A - if &quot;%APPVEYOR_REPO_BRANCH%&quot;==&quot;master&quot; if not defined APPVEYOR_PULL_REQUEST_NUMBER (git diff --quiet --exit-code --cached || git commit -m &quot;Update Static Site&quot; &amp;&amp; git push origin %TARGET_BRANCH% &amp;&amp; appveyor AddMessage &quot;Static Site Updated&quot;) 然后在UI设置的Environment里,添加四个环境变量:STATIC_SITE_REPO(是要提交到的repo地址,也就是我静态页面库的地址)，TARGET_BRANCH(repo分支,填master即可)，GIT_USER_EMAIL(GitHub账户的邮箱)和GIT_USER_NAME(GitHub账号用户名),贴上我的供参考:当然, 你也可以直接在配置文件里修改, 直接将环境变量改成相应的值即可. 这样再推送就可以看到appveyor自动进行build了. 赘述 使用appveyor期间遇到了比较诡异的情况:提交后有时候会build成功, 有时候会build失败, 有时候失败了再build一次就成功了, 有时候失败了再build好几次成功不了, 完全是概率问题.以下是错误日志: *html .test{color:#090;} /* For IE6 and earlier */ *+ html .test{color:#ff0;} /* For IE7 */ .test:lang(zh-cn){color:#f00;} /* For IE8+ and not IE */ .test:nth-child(1){color:#0ff;} /* For IE9+ and not IE */ 看日志好像是权限的问题，Google了一下, 在appveyor官方的github账户中的该issue中提到了将npm版本安装为5.3即可:npm -g install npm@5.3，到底还是版本的问题 如果创建project时选择的是Git, 即使用Clone URL的方式添加git repo来创建项目的话, 那么源项目中即便有appveyor.yml配置文件也无法使用, 其原因被我在appveyor官方github的一个issue中找到, 因为配置文件的工作原理是appveyor在build创建之前通过Github等托管方提供的API先将配置文件下载下来再自动对运行环境进行配置, 而是使用这个API是需要access token的, 当然, 你可能要问”为什么不直接去下appveyor.yml文件?而非要使用API呢?像octotree一类的插件不就是可以直接下载么?”可是octotree的项目中也说了它也是用的api:Octotree uses GitHub API to retrieve repository metadata. By default, it makes unauthenticated requests to the GitHub API. However, there are two situations when requests must be authenticated:1.You access a private repository2.You exceed the rate limit of unauthenticated requestsWhen that happens, Octotree will ask for your GitHub personal access token. If you don’t already have one, create one, then copy and paste it into the textbox. Note that the minimal scopes that should be granted are public_repo and repo (if you need access to private repositories).关于API调用速率限制的github官方说明, 简而言之, 未登录则对ip进行限制, 每小时60次;使用登录认证或OAuth token则对用户进行限制, 每小时5000次;所以如果appveyor要使用API的话肯定是使用认证的方式.再回到git方式创建的项目无法使用配置文件的问题上, 你可能要问”既然我在appveyor的账户里填了我的github personal access token, 为什么官方不在这个创建方式上做些判断, 检测到是GitHub/BitBucket等的项目就带上token去拉”, 这……你还不如登录自己的GitHub账号直接fork这个项目, 然后在appveyor里选择github方式创建项目, 万事大吉.总而言之, 如果使用git方式创建项目的话, 就只能使用GUI的方式来配置项目, 不能在git仓库里使用配置文件的方式.]]></content>
      <tags>
        <tag>CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派入门]]></title>
    <url>%2F%2Fpost%2F%E6%A0%91%E8%8E%93%E6%B4%BE%E5%85%A5%E9%97%A8.html</url>
    <content type="text"><![CDATA[对于入手树莓派 是蓄谋已久现在如愿以偿。本文整理了使用过程中遇到的一些问题。 盒子在实际使用之前建议你买一个盒子, 因为树莓派本身只有一块板子, 如果板子发生弯曲的话里面的印制线路很可能会被折断(树莓派的线路是多层压制在一起的,像一块三明治一样), 而且很多焊点和组件很可能因为你的操作不当(比如把它放在铁质桌子这种导体上)而发生短路, 有了盒子也就多了一层保护. 安装系统 下载镜像raspberryPi官方的镜像集合在这里，kali的镜像在这里 安装安装系统的网上教程很多，我使用的是Raspbian系统,用rufus直接烧录进去tf卡里；当然也可以将镜像烧录到U盘，然后开机进bios从U盘安装系统，这种方法需要使用显示器和有线键盘。 指示灯简介树莓派上除了rj45网口的led指示灯（speed led【黄灯】：长亮代表100M或者更高速的网卡，不亮代表10M网卡，但有些千兆网卡的灯以颜色区分，不亮代表10M/100M，黄色常亮代表1000M；active led【绿灯】：灯灭代表未连接，长亮代表已连接上但无数据收发，闪烁代表有数据收发）外在电源接口处还有两个状态灯，一个红灯一个绿灯，红灯是电源灯，接通后常亮，如果闪烁说明当前电源不稳定；绿灯是读写指示灯，在存储卡发生数据读写时闪烁，否则熄灭，以此来判断当前是否发生数据读写。 连接注意: 系统默认ssh服务不随机自启动，我们将tf卡插在笔记本上，在显示出的boot分区中创建一个名为ssh的空白文件来触发ssh服务的开启 网线直连笔记本我采用的方式是笔记本网线直连树莓派，然后将笔记本无线网卡的网络共享给以太网卡，这样不仅树莓派能够上网，我也能ssh到树莓派。网线连接好、树莓派主板加电启动之后，我们使用arp命令扫描一下本地的mac与ip映射表，并抓取出树莓派的地址映射： C:\Users\jay&gt; arp -a |findstr &quot;b8-27-eb&quot; 192.168.137.232 b8-27-eb-8e-9e-fe 静态 “b8-27-eb”是树莓派网卡mac地址的前三个字节，也就是树莓派制造商的OUI（组织唯一识别符），从IEEE官方提供的OUI列表，我们可以查询到。获取到ip后我们使用ssh连接，默认用户名为pi，密码为raspberry。 路由器连接如果第一次启动的时候手边没有网线，但是有路由器，可以配置Wi-Fi连接。和第一次开机触发SSH服务的方法一样，将tf卡插在笔记本上，在显示出的boot分区中建立名为wpa_supplicant.conf的文件，里面添加如下内容： country=GB ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=&quot;Wi-Fi名称&quot; psk=&quot;Wi-Fi密码&quot; priority=填写数字，数字越大代表优先级越高 } 树莓派主板加电，稍等几分钟，就会连上Wi-Fi了。 连接显示器遇到的问题我有一次在连接显示器的时候突然黑屏了，在网上搜索一下后得知需要修改boot目录下的config.txt文件，将hdmi_safe=1的注释取消掉。可以参考该教程解决使用显示器的问题 使用root账号root账号默认未启用，如果要使用root账号，我们需要: #设置root账号密码 sudo passwd root #启用root账号 sudo passwd --unlock root 如非必要不建议使用，毕竟账号pi使用sudo无需输入命令，方便的同时也更安全。 使用wifi可以直接编辑/etc/wpa_supplicant/wpa_supplicant.conf文件，在后面追加 network={ ssid=&quot;Wi-Fi名称&quot; psk=&quot;Wi-Fi密码&quot; priority=填写数字，数字越大代表优先级越高 } #如果有多个可选wifi可以继续添加 network={ ssid=&quot;第二个Wi-Fi的名称&quot; psk=&quot;第二个Wi-Fi的密码&quot; priority=填写数字，数字越大代表优先级越高 } network={ ssid=&quot;第三个Wi-Fi的名称&quot; psk=&quot;第三个Wi-Fi的密码&quot; priority=这里填写数字，数字越大代表优先级越高 } #以此类推 完成后重启即可 静态ip有些时候你拔下网线后重新插回去，会导致树莓派重新获取ip，遇到如下的尴尬情况 C:\Users\jay&gt; arp -a |findstr &quot;b8-27-eb&quot; 192.168.137.232 b8-27-eb-8e-9e-fe 静态 192.168.137.240 b8-27-eb-8e-9e-fe 静态 出现了两个地址映射,这是因为重新插回去后树莓派被分配了一个新的ip,而之前的地址映射还存在arp地址映射表中,所以就出现了两个结果.我们可以编辑dhcpcd.conf配置文件来主动获取静态ip sudo vi /etc/dhcpcd.conf 在文件中添加（如果嫌弄乱文件可以搜索”profile static_eth0”这个pattern然后在后面进行修改） #根据自己的实际情况来，以下只是我的配置，仅供参考 interface eth0 static ip_address=192.168.137.232/24 static routers=192.168.137.1 static domain_name_servers=192.168.137.1 完成后重启即可注：千万不要像网上有些教程一样修改/etc/network/interfaces文件进行配置，这样一定是不成功的，因为该文件中已经标注的很清楚了： #For static IP, consult /etc/dhcpcd.conf and &#39;man dhcpcd.conf&#39;]]></content>
      <tags>
        <tag>硬件</tag>
        <tag>raspberry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校园网中实现免费上网的方法（一）]]></title>
    <url>%2F%2Fpost%2F%E6%A0%A1%E5%9B%AD%E7%BD%91%E4%B8%AD%E5%AE%9E%E7%8E%B0%E5%85%8D%E8%B4%B9%E4%B8%8A%E7%BD%91%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89.html</url>
    <content type="text"><![CDATA[这个学期我们学校的校园网开始了流（变）量（相）计（卷）费（钱）的策略，不过运营商可以进行代理，所以有的同学使用指定的手机套餐就可以不限流量。但是我的手机卡并不是校园卡，所以使用的还是校园网的单独计费策略，当然套餐里的这点流量对于喜欢看点剧的我肯定是不够用的。平时因为学校机房中有几台服务器在我手里，使用校内流量走代理免费上网完全是没问题的，但是国庆期间因为各种原因，校内服务器对外网络基本全部封闭了，所以代理是走不了了，可是剧还是要看的啊，于是就有了这篇博客。 原理原理很简单，AP使用的是DHCP自动分配ip的策略，我们扫一遍本地网络中的机器，一般都会有在上网的PC，因为AP根据这台PC的mac分配给了它IP地址，而且这台PC登陆了校园网所以已经获取了访问外网的权限，也就是说这个PC的IP是可访问外网的，我们只要拿到它就行了。 因为是DHCP自动分配，所以我们只要拿到它的mac地址就能拿到IP（这种扫描器有很多，nmap也可以），我们先把网断掉，然后到系统的设置里面将网卡的mac地址修改成与之前扫描到的PC一致（这样的修改只是修改了操作系统从网卡中读取并记录在系统中的mac地址的值，并非修改了烧录在网卡中的地址，所以与“mac地址不可修改的说法并不冲突”，当然了，修改烧录的地址也并非不可行，但是这种硬件操作的方法对用户的专业素质要求很高，因为复杂度高风险也大），然后重新启动网卡，连接到AP，查看自己获取到的IP是不是变得跟之前扫描的PC的ip一致，一致则说明欺骗成功，到登录的认证页面刷新查看，显示出来的登录用户应该是PC的主人。 在此只讨论方法，对步骤不进行详细说明。 问题值得一提的是，这种mac地址欺骗的方法得到的免费上网质量可能比较差，因为在AP看来从外网接收到的数据是一个目标的，但实际上是两台电脑在上网，所以数据包的分发会存在问题，可能就会导致服务掉线、下载文件走走停停之类的结果（我测试时使用了室友的mac地址，他的qq出现了掉线情况，我的迅雷下载时走时停），所以如果只是下载电影什么的还是可以的，放在那让它慢慢跑就可以了，但是打局游戏什么的就不要想了。 赘述当然了，上面只是测试下我想法的可行性，实验一下玩玩罢了，实际并没有这么做的必要，毕竟那么多同学是运营商免流的，需要下载大文件临时借个账号就可以了。 对于之前提到的服务器代理校内流量出去的问题，用pip装个影梭代理一下就可以了，就简单的使用上并没什么技术可言，网上之类的教程也很多，如果学校使用的是提供ipv6地址的网络（如教育网），那么校外的有ipv6地址的服务器也是可以的，因为现在校园网ipv6应该都是不计费的（不绝对，天知道你的学校为了安（赚）全（钱）会做出什么出格的事），流量可以直接出去。 在这过程中，我遇到的一个问题就是：服务器有v6地址，本地PC也有v6地址，两个都可以单独访问Google，但是PC走服务器代理的话就无法访问Google一类被墙掉的网站，服务器使用的是双栈代理，而且PC此时也可以访问六维一类的v6站点，说明v6流量是出的去的，对此我做了很多测试，但仍毫无头绪，如果有朋友知道其中的缘由，还望告知。 本文提及的方法仅供安全学习，禁止非法利用]]></content>
      <tags>
        <tag>运用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于php下实现异步计划任务的一种方法]]></title>
    <url>%2F%2Fpost%2F%E5%85%B3%E4%BA%8Ephp%E4%B8%8B%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[在一个网络管理系统的实现过程中需要完成这样一个功能，老师在上课时通过交互界面将该教室的网络关闭，课程结束后系统将自动将教室网络开放，这有两方面的要求，首先是计划任务的实现：下课后自动恢复网络，这里使用循环来检查任务执行情况，因为如果全部都写到操作系统的计划任务中那就太繁重了（当然也可以只写一个系统的计划任务，将它和数据库结合起来实现，这是我最后采用的方法）；二就是老师提交“关闭网络”的请求时应当异步处理，因为计划任务是死循环，如果不进行异步处理则页面将永远处于加载状态直到用户强制阻断或任务执行结束。 具体过程计划任务唯一化因为一堂课上可能会多次切换网络状态，所以必须让当前教室的网络恢复计划任务唯一化，新的计划任务应当取代旧的，这里我使用文件flag的方式来实现：用$_SESSION[‘ID’]加上当前时间戳的方式来命名flag文件，$_SESSION[‘ID’]为用户ID，由于老师一堂课只能在一个教室上课，所以这是唯一的；当前时间戳（time()函数获取）精确到秒，足够保证用户在这个时间段内操作唯一。每一次生成计划任务时我们都生成这样一个文件保存在flag文件夹中，并将文件名传给任务函数，让它去检查这个文件状态，存在的话则任务有效，否则终止任务；相对的，生成新任务时，我们把flag文件夹中的所有以当前$_SESSION[‘ID’]开头的flag文件全部删除，再生成新的任务和flag，这样旧的任务就会失效，由此保证任务的唯一性。 异步这里是用fsockopen函数来实现异步，这样实现的好处就是有很大的自定义空间，例如相比于popen()函数的不可传递参数。 代码//user.php //作用：用户交互界面，提交数据给set-network.php //代码如下： $url = &quot;http://localhost:8081/tch/set-network.php&quot;; sock_get($url, $_GET[&quot;network&quot;], $_GET[&quot;classroomName&quot;],$endTimestamp); //fsockopen模拟get提交函数 function sock_get($url, $network, $classroomName, $endTimestamp) { //设置get提交的数据 $data = array( &quot;network&quot; =&gt; $network, &quot;classroomName&quot; =&gt; $classroomName, &quot;endTimestamp&quot; =&gt; $endTimestamp); $http_data = http_build_query($data); $info = parse_url($url); $fp = fsockopen($info[&quot;host&quot;], $info[&quot;port&quot;], $errno, $errstr, 3); $head = &quot;GET &quot; . $info[&#39;path&#39;] . &quot;?&quot; . $http_data . &quot; HTTP/1.0\r\n&quot;; $head .= &quot;Host: &quot; . $info[&#39;host&#39;] . &quot;:&quot; . $info[&#39;port&#39;] . &quot;\r\n&quot;; $head .= &quot;\r\n&quot;; fputs($fp, $head); fclose($fp); } //set-network.php //作用：从用户操作接收数据用来生成计划任务 //代码如下： require &quot;restore-network.php&quot; //查找当前用户有无已存在的flag，有的话删除，即终止已存在的恢复网络计划任务 $search = glob(&quot;./flags/&quot; . $_SESSION[&#39;ID&#39;] . &quot;*&quot;); if ($search) { foreach ($search as $item) { unlink($item); } } $flag = &quot;./flags/&quot; . $_SESSION[&quot;ID&quot;] . time() . &quot;.flag&quot;; file_put_contents($flag, &quot;&quot;, FILE_APPEND); $schedule = new restore_network(); $schedule-&gt;keepWake($flag, $endTimestamp); //restore-network.php //作用：计划任务和恢复网络的功能实现 //代码如下： ignore_user_abort();//关掉浏览器，PHP脚本也可以继续执行. set_time_limit(0);//设置不响应最长时间不受限制,让程序可以无限制的执行下去 //定时任务函数，不断循环来定时执行任务 function keepWake($flagFile, $endTimestamp) { //当前时间戳比结束时间戳小则一直循环 while (time() &lt; $endTimestamp) { // 定时任务终止条件:本任务的flag文件不存在 if (!file_exists($flagFile)) { die(&#39;process terminated&#39;); } sleep(120); } //删除flag文件 unlink($flagFile); //执行恢复网络功能函数，这不是重点，在此忽略函数内容 $this-&gt;restoreNet(); } 赘述尽管我最后用的并不是这种解决办法，因为考虑到万一web服务器软件宕掉的话那么这些计划任务都会丢失，我采用了将定时任务所需的参数存入数据库，再将一个php脚本写入操作系统计划任务中（如linux的crontab），每隔几分钟执行一遍，由这个脚本去数据库查询是否有到期的定时任务，有的话则调出数据进行执行，再数据库中相应的任务删除。整个过程可能考虑的不是很周到，只能算是一个实现目标的方法。]]></content>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php部分版本使用oci8拓展问题]]></title>
    <url>%2F%2Fpost%2Fphp%E9%83%A8%E5%88%86%E7%89%88%E6%9C%AC%E4%BD%BF%E7%94%A8oci8%E6%8B%93%E5%B1%95%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[最近在使用php实现从服务器Oracle数据库拉取数据表到本地mysql功能时遇到了这个问题：我使用的是xampp集成的php5.6.3版本，在它的php.ini配置文件中关于oci8拓展的配置是这样的： extension=php_oci8_12c.dll ; Use with Oracle Database 12c Instant Client 从Oracle官网下载instantclient-basic-nt-12.2.0.1.0.zip拓展，解压后我把得到的instantclient_12_2目录移动到C:\Program Files下并加入环境变量，但是idea运行项目时一直在报: PHP Warning: PHP Startup: Unable to load dynamic library &#39;C:\xampp\php\ext\php_oci8_12c.dll&#39; 导致oci8接口函数，如oci_connect等无法使用。 解决过程在把stack overflow翻了个遍之后找到了可行的解决办法——放弃php_oci8_12c.dll，将其更换为其他的版本。 去pecl下载其他版本的OCI8 extension下载地址，我选择了2.0.10版本，这是支持php5的最后一个版本，注：下载dll动态链接库文件需要点击”oci8-2.0.10.tgz (186.9kB)”链接后面的”（windows田字图形）DLL”链接，这是下载直达链接，根据自己的php版本下载合适的。 替换文件将解压后的下载文件移动到php拓展目录（即extension_dir）,然后在php.ini中加上 extension=php_oci8_11g.dll 去 Oracle官网下载相应的instant client V11，解压后把目录添加进系统变量。 检查cmd输入”PHP –ri oci8” C:\WINDOWS\system32&gt;PHP --ri oci8 结果显示： oci8 OCI8 Support =&gt; enabled OCI8 DTrace Support =&gt; disabled OCI8 Version =&gt; 2.0.8 Revision =&gt; $Id: f04114d4d67cffea4cdc2ed3b7f0229c2caa5016 $ Oracle Run-time Client Library Version =&gt; 11.2.0.1.0 Oracle Compile-time Instant Client Version =&gt; 11.2 Directive =&gt; Local Value =&gt; Master Value oci8.max_persistent =&gt; -1 =&gt; -1 oci8.persistent_timeout =&gt; -1 =&gt; -1 oci8.ping_interval =&gt; 60 =&gt; 60 oci8.privileged_connect =&gt; Off =&gt; Off oci8.statement_cache_size =&gt; 20 =&gt; 20 oci8.default_prefetch =&gt; 100 =&gt; 100 oci8.old_oci_close_semantics =&gt; Off =&gt; Off oci8.connection_class =&gt; no value =&gt; no value oci8.events =&gt; Off =&gt; Off Statistics =&gt; Active Persistent Connections =&gt; 0 Active Connections =&gt; 0 cmd输入”php -r “var_dump(function_exists(‘oci_connect’));”” C:\WINDOWS\system32&gt;php -r &quot;var_dump(function_exists(&#39;oci_connect&#39;));&quot; 结果显示： bool(true) 则已成功。 注意idea需要重启电脑后方可使用oci8拓展的相关接口函数（我尝试过”synchronize”和”Invalidate Caches / Restart”功能，都无效），否则仍然会提示找不到动态链接库文件。也可能是因为我使用的是php内置的服务器问题，在此提一下。 赘述这个问题的存在不知道是xampp的锅还是这个php版本的锅，总而言之问题现在是解决了，算是有所收获吧，所以总结一下。其他版本若出现相似问题也可以参考。]]></content>
      <tags>
        <tag>php</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度网盘下载高速通道延时]]></title>
    <url>%2F%2Fpost%2F%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E4%B8%8B%E8%BD%BD%E9%AB%98%E9%80%9F%E9%80%9A%E9%81%93%E5%BB%B6%E6%97%B6.html</url>
    <content type="text"><![CDATA[百度网盘PC客户端下载有300秒的高速通道试用，而“300”不过是个存在内存中的数值，借助于 Cheat Engine 这样的内存扫描工具，我们可以任意修改其大小。 步骤 首先上 官 网 下载CheatEngine并安装。 打开百度网盘客户端 和 CheatEngine（以下简称CE）。CE左上角file下有个小电脑在闪烁，如图，打开它。 然后从程序列表里选择百度网盘客户端，如图，打开； 开始下载所需要的文件，然后点击试用高速通道； 立即切换到CE，在Value输入框中设定一个值，如257，当百度网盘高速通道试用时间变成257时，点击New Scan按钮对百度网盘客户端占用的内存进行扫描； 扫描后会发现左侧列表中会展示出很多查找到的内存地址，找到value一栏中的值和百度网盘客户端高速通道试用时间的值相同的一项，双击选中，到下面的操作栏中进行修改； 双击修改剩余时间，由于存放地址是4字节大小的内存，所以最大的值只能为(2^32)-1=4294967295，如果值比这个数大会导致溢出，CE会将其随机降为一个比4294967295小的较大值。 修改完成，可以关闭CE。 赘述CE这种内存扫描器其实有很多，我自己接触的第一款就是初中时候在Symbian系统上使用的“八门神器”，用来修改手机中小游戏的各种参数，弹药量、生命值之类。 以上方法只适用于有试用高速通道的时候，像有的时候没有试用高速通道的机会便没法进行加速。建议修改成较大的值（注：发现如果在修改过一次的基础上修改第二次会将剩余时间卡死。实际并没有所谓，因为时间值足够大），就算下载完毕之后不要马上关闭客户端（因为下次打开可能就没有试用高速通道的机会），高速通道的剩余时间仍会继续跑。 虽然有时间限制，但是修改的值较大的话基本可以忽略这个限制。可以说唯一的限制在于试用高速通道的机会。 我在学校内使用ipv6走高速通道网络状态好的时候速度还是挺让人满意的。 以上。]]></content>
      <tags>
        <tag>百度网盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows热点不可用解决办法]]></title>
    <url>%2F%2Fpost%2Fwindows%E7%83%AD%E7%82%B9%E4%B8%8D%E5%8F%AF%E7%94%A8%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html</url>
    <content type="text"><![CDATA[该问题的现象表现为windows热点开启成功，且在移动端可以正确进行密码的认证，但就是无法连接上或是连接上之后无法上网（移动端此时已通过dhcp获取到ip）。 解决办法法一.首先想到的当然是对本地热点的重启，若重启后仍然无效，参考法二； 法二. 1.在网络适配器管理（控制面板\网络和 Internet\网络连接）中将你的热点连接禁用； 2.进设备管理器（win+x键调出选项栏后按M键选择设备管理器），菜单栏中“查看”选中“显示隐藏的设备”，在下面打开网络适配器一栏，会有一个图标带向下箭头（已被禁用）的 network virtual Adapter（虚拟网络适配器），不同的电脑因为网卡不同或者oem定制的问题可能会导致适配器名字不一样，根据具体情况自己选择。双击它，“启用设备”。 完成以上步骤后再启动自己的热点 赘述以上方法是我在遇到该问题后自己摸索出来的，在我的电脑上可解决问题。如果无法解决你所遇到的问题，建议搜索其他的解决办法。]]></content>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(xrdp+vnc)远程linux桌面]]></title>
    <url>%2F%2Fpost%2F(xrdp%2Bvnc)%E8%BF%9C%E7%A8%8Blinux%E6%A1%8C%E9%9D%A2.html</url>
    <content type="text"><![CDATA[相信大家桌面远程linux服务器大多用的都是vnc（虽然对于linux系统桌面远程用的确实很少），这里提一下xrdp的优势，1.加密，vcn本身的传输是不加密的（可以借助于SSL实现）；2.因为xrdp实质上就是一个 rdp 服务器，所以我们在windows上只需要借助自带的mstsc就可以直连linxu桌面系统，因为都使用了rdp协议，很方便；3. 支持多用户登录；4.第四个优势…要说第四个优势的话……开源算么？（逃… 操作步骤安装xrdp+vncserver：#CentOS yum install epel-release yum update yum install xrdp tigervnc-server #Ubuntu apt-get update apt-get install xrdp tigervnc-server 如果服务器桌面系统都没装的话，建议选择xfce一类轻量型桌面 #CentOS yum groupinstall xfce4 #Ubuntu apt-get install xubuntu-desktop #安装完成后运行 systemctl set-default graphical.target #使系统默认从GUI启动 #如果要恢复默认从CLI启动 systemctl set-default multi-user.target #使系统默认从CLI启动 设置xrdp开机自启：systemctl enable xrdp.service #启动xrdp服务 systemctl start xrdp 如果xrdp报错的话可以参考 该链接 ，运行： #Allow SElinux to allow: chcon --type=bin_t /usr/sbin/xrdp chcon --type=bin_t /usr/sbin/xrdp-sesman #Start it systemctl start xrdp 运行”vncserver”命令在当前用户家目录实例化vnc配置#如果想以其他用户的身份连接远程连接，需要先使用su命令来切换用户 vncserver 配置vncserver服务：cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:&lt;NUMBER&gt;.service #&lt;NUMBER&gt;为数字 #将/etc/systemd/system/vncserver@:&lt;NUMBER&gt;.service中的&lt;USER&gt;替换为你的用户名，共两处。 #如果是root用户的话，其中的家目录需要改为/root，而非/home/&lt;USER&gt; systemctl重新加载配置文件systemctl daemon-reload 防火墙允许服务注意iptables规则是否有拦截xrdp和vnc服务访问网络。 Centos7及以上上需要配置firewall允许xrdp和vnc:firewall-cmd --permanent --zone=public --add-port=3389/tcp #允许xrdp（默认端口为3389） firewall-cmd --permanent --zone=public --add-service=vnc-server firewall-cmd --reload 启动vncsystemctl start vncserver@:&lt;Nummer&gt;.service 赘述Windows上mstsc直连session需要选择xvnc 如果需要以root身份登录，则需要以root身份运行vncserver,配置vncserver@:{n}.service文件后，在/home目录创建root文件夹，将其链接到/root目录即可 若使用vnc客户端连接的话，分辨率可能会导致无法满屏显示，这时可以直接修改vnc的分辨率( 参考链接 )： 如果要使用的分辨率在现有的模式中没有的话，我们可以自己手动添加1.首先查询所需要参数，cvt 加分辨率例如我需要1366*768的分辨率，则输入“cvt 1366 768”，查询该分辨率的有效扫描频率是多少将Modeline “1368x768_60.00” 后面的“85.25 1368 1440 1576 1784 768 771 781 798 -hsync +vsync”参数复制2.创建所需的模式 xrandr --newmode &quot;模式名&quot; + 上一步复制的参数 3.这时接使用刚刚创建的模式会提示找不到模式，需要手动添加一下 xrandr --addmode 显示器名 &quot;模式名&quot; 创建成功：添加成功：4.使用新建模式 xrandr --output 显示器名 --mode &quot;模式名&quot; 当前设置在重启后失效，可以将其写入配置文件保证设置永久有效 分辨率也可以通过vnc客户端设置，但是画质会受影响本文部分参考 该博文]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime下markdown环境配置]]></title>
    <url>%2F%2Fpost%2Fsublime%E4%B8%8Bmarkdown%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[因为用的挺顺手的，所以推荐一下。我在sublime上编写markdown文档的环境配置是: Markdown Editing + OmniMarkupPreviewer + Markdown Extended + Monokai Extended 插件介绍MarkdownEditing作为sublime上编写Markdown必备的插件，不仅可以高亮显示Markdown语法还支持很多编程语言的语法高亮显示（需要主题支持）。 OmniMarkupPreviewer用来渲染和预览markdown文档的效果。 这两个插件安装完了以后我们在编写markdown时会发现Markdown文档在Sublime中是默认无高亮的，而且很多主题也不支持Markdown的高亮，而Monokai Extended和Markdown Extended 的组合很好的解决了这个问题。 以上插件都安装完成后，重启sublime，然后在preferences-&gt;color scheme-&gt;Monokai Extended 选择一项你顺眼的作为配色模式，再将Markdown Extended选为markdown文档的语法规则即可（view-&gt;systax-&gt;open all with current extension as 如图）： Tips 1.具体的markdown语法可以参照wowubuntu上的 这一篇文章 2.插件使用的小技巧去搜一下就有了，在此就不赘述了]]></content>
      <tags>
        <tag>sublime</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拓展chrome插件json-viewer]]></title>
    <url>%2F%2Fpost%2F%E6%8B%93%E5%B1%95chrome%E6%8F%92%E4%BB%B6json-viewer.html</url>
    <content type="text"><![CDATA[最近在学习维护学校iptv服务器时获得了电视墙缓存图片的json数据，chrome打开页面后jsonViewer无法格式化代码，如图（jsonViewer此时并没有启动，它并不格式化本地文件）： google上找了一下，发现了 网友自己拓展的json-viewer ，与 http://www.jsonohyeah.com/上的效果相近，不过可以本地格式化，省去联网了，觉得很好用。觉得样式丑的可以去github拉取代码自己改下样式（样式表在WebContent\viewer\index.html文件中），然后chrome打包拓展程序安装。 提醒注1：打包目录选择WebContent，否则会报错“清单文件缺失或不可读”注2：报错“指定扩展程序的私有密钥已存在。请重复使用该密钥，或者先删除它” 则删除 从github拉取得到的master分支下pem密钥文件即可。最终效果如图： 本人已修改样式且打包了的拓展程序在此注3：直接安装crx包可能会在之后因为安全问题被chrome永久禁用，解决办法有二,1.可以开启开发者模式，选择“加载已解压的拓展程序”，从JSONView-for-Chrome-master\WebContent文件夹直接安装源码， 这样安装后就不会有这种问题,但是每次打开chrome都会提醒你禁用开发者模式下安装的拓展。2.按照 该网址的方法二 进行操作，方法一我测试过，在我电脑上（win10）是无效的，我不知道问题在哪，可能是注册表键值的有效位置在win10上改动了。但是法二有个局限就是自win8开始组策略只在专业版及以上版本才有。以上。]]></content>
      <tags>
        <tag>chrome</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web应用从网页插入中文到mysql变成乱码的解决办法]]></title>
    <url>%2F%2Fpost%2Fweb%E5%BA%94%E7%94%A8%E4%BB%8E%E7%BD%91%E9%A1%B5%E6%8F%92%E5%85%A5%E4%B8%AD%E6%96%87%E5%88%B0mysql%E5%8F%98%E6%88%90%E4%B9%B1%E7%A0%81%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html</url>
    <content type="text"><![CDATA[相信既然这么进来了，那么问题肯定是差不多的，下面直接讲述解决办法： 解决办法首先在mysql配置文件my.ini中进行配置修改#搜索找到[mysqld]，在它下面添加配置，如下 [mysqld] character-set-server = utf8 #搜索找到[mysql]，在它下面添加配置，如下 [mysql] default-character-set = utf8 修改连接编码和中文字段编码接下来我是从phpmyadmin上操作的，如果你没有可视化操作界面，那就转换成sql语句来操作吧。 set names &quot;utf8&quot;; 再将所有需要插入中文的字段进行结构修改：例如下面的message字段 将排序规则修改为utf8_general_ci 赘述我曾多次遇到这种问题都是这么解决的，也曾利用修改排序规则的方法帮同学结果过类似问题，在此仅供参考。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
</search>
